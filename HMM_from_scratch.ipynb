{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMM_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsJGymgQrce1"
      },
      "source": [
        "# Import required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4CeZyBOX8XQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYZahMweZttK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c783617-1fa6-4bad-e646-67137f534373"
      },
      "source": [
        "cd drive/MyDrive/EECS738-Project2/notebooks/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EECS738-Project2/notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f10s7GujrhbT"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEDt_nnAYPL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "01e55da8-a1af-46f9-f846-f5f212855553"
      },
      "source": [
        "df = pd.read_csv(\"../data/Shakespeare_data.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACT I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SCENE I. London. The palace.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.1</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.2</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dataline  ...                                         PlayerLine\n",
              "0         1  ...                                              ACT I\n",
              "1         2  ...                       SCENE I. London. The palace.\n",
              "2         3  ...  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...\n",
              "3         4  ...             So shaken as we are, so wan with care,\n",
              "4         5  ...         Find we a time for frighted peace to pant,\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB_D2nCNZ_TW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638dc7a5-53f1-4e90-db25-df5f8ed9fbb9"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 111396 entries, 0 to 111395\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Dataline          111396 non-null  int64  \n",
            " 1   Play              111396 non-null  object \n",
            " 2   PlayerLinenumber  111393 non-null  float64\n",
            " 3   ActSceneLine      105153 non-null  object \n",
            " 4   Player            111389 non-null  object \n",
            " 5   PlayerLine        111396 non-null  object \n",
            "dtypes: float64(1), int64(1), object(4)\n",
            "memory usage: 5.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVZj24rUaNyd"
      },
      "source": [
        "***Let's look deeper at the datasets given***<br>\n",
        "*column_name (type of column) \n",
        "    - description*\n",
        "\n",
        "The shakespeare dataset contains the following columns :\n",
        "- Dataline (int) ***seems useless***\n",
        "    - A unique id for each line.\n",
        "- Play (str) \n",
        "    - Name of the play where the lines are from\n",
        "- PlayerLineNumber (int) \n",
        "    - The real line number that are being spoken \n",
        "    - Difference with ActSceneLine's Line\n",
        "        - PlayerLineNumber is one whole long sentence and the ActSceneLine is the small cut part of PlayerLineNumber\n",
        "        - PlayerLinenNumber resets in new scene\n",
        "- ActSceneLine (str) \n",
        "    - Comes in 1.1.1 (Act is 1, Scene is 1, Line is 1)\n",
        "- Player (str)\n",
        "    - The character name in the play\n",
        "- PlayerLine (str)\n",
        "    - The line spoken by the player \n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4guat1jaNfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "496675be-daec-4cfc-b4c2-fb7054a7efb0"
      },
      "source": [
        "df = df.dropna()\n",
        "df.reset_index(inplace=True,drop=True)\n",
        "df.drop([\"Dataline\",\"Play\",\"PlayerLinenumber\",\"ActSceneLine\",\"Player\"], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And breathe short-winded accents of new broils</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To be commenced in strands afar remote.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No more the thirsty entrance of this soil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       PlayerLine\n",
              "0          So shaken as we are, so wan with care,\n",
              "1      Find we a time for frighted peace to pant,\n",
              "2  And breathe short-winded accents of new broils\n",
              "3         To be commenced in strands afar remote.\n",
              "4       No more the thirsty entrance of this soil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d0HGsi_ioOy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fdf6df4d-fcea-4ead-f027-4c6aca1a1022"
      },
      "source": [
        "df[\"PlayerLine\"] = df[\"PlayerLine\"].str.replace(r'[^\\w\\s]', '').str.lower()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>so shaken as we are so wan with care</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>find we a time for frighted peace to pant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and breathe shortwinded accents of new broils</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to be commenced in strands afar remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no more the thirsty entrance of this soil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      PlayerLine\n",
              "0           so shaken as we are so wan with care\n",
              "1      find we a time for frighted peace to pant\n",
              "2  and breathe shortwinded accents of new broils\n",
              "3         to be commenced in strands afar remote\n",
              "4      no more the thirsty entrance of this soil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BQVI57K57M2"
      },
      "source": [
        "# Build our Hidden Markov Model\n",
        "- Our emission will be the word from the text\n",
        "- Our hidden state will be the starting letter of the word. (A better hidden state would be Noun, Verb, etc. Meaningful hidden state will helpful in building a better HMM model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF_fFPMsdg7L"
      },
      "source": [
        "list_of_token = []\n",
        "list_of_token_starting_letter = []\n",
        "for line in df[\"PlayerLine\"]:\n",
        "  for word in line.split():\n",
        "    list_of_token.append(word)\n",
        "    list_of_token_starting_letter.append(word[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88s-sR8p5hmn"
      },
      "source": [
        "For simplicity only taking the first 100 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXMFYXt4kQ4c"
      },
      "source": [
        "# list_of_token = [\"this\", \"is\", \"a\", \"apple\", \"a\"]\n",
        "# list_of_token_starting_letter = [\"t\", \"i\", \"a\", \"a\", \"a\" ]\n",
        "\n",
        "list_of_token = list_of_token[:100]\n",
        "list_of_token_starting_letter = list_of_token_starting_letter[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh8yHk6R5pkW"
      },
      "source": [
        "Change strings to numbers for easier usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaus1FNWifgM"
      },
      "source": [
        "LE_1 = preprocessing.LabelEncoder()\n",
        "list_of_token = LE_1.fit_transform(list_of_token)\n",
        "\n",
        "LE_2 = preprocessing.LabelEncoder()\n",
        "list_of_token_starting_letter = LE_2.fit_transform(list_of_token_starting_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84LnRU0U5xff"
      },
      "source": [
        "## Calculation of initial probability, transition probability, emission probabilty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD4FYQbx01cF"
      },
      "source": [
        "initial_state_matrix = []\n",
        "length= len(list_of_token)\n",
        "\n",
        "for i in sorted(set(list_of_token)):\n",
        "  number_of_token =  len(np.where(list_of_token==i)[0])\n",
        "  initial_state_matrix.append(number_of_token/length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsvcQO2ZSLEg"
      },
      "source": [
        "initial_hidden_state_matrix = []\n",
        "length= len(list_of_token_starting_letter)\n",
        "\n",
        "for i in sorted(set(list_of_token_starting_letter)):\n",
        "  number_of_token =  len(np.where(list_of_token_starting_letter==i)[0])\n",
        "  initial_hidden_state_matrix.append(number_of_token/length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL7iFtRGhwWp"
      },
      "source": [
        "# Transition matrix\n",
        "transition_matrix = []\n",
        "number_of_hidden_states = 1 + int(max(list_of_token_starting_letter))\n",
        "temp_matrix = np.zeros(shape=(number_of_hidden_states,number_of_hidden_states))\n",
        "\n",
        "temp = True\n",
        "for i in range(0,number_of_hidden_states):\n",
        "    list_of_index = list(np.where(list_of_token_starting_letter==i)[0])\n",
        "    for index in list_of_index:\n",
        "        if((index+1) != len(list_of_token_starting_letter)):\n",
        "            temp_matrix[i,list_of_token_starting_letter[index+1]] += 1/len(list_of_index)\n",
        "\n",
        "transition_matrix = temp_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7gjRBmppEb8"
      },
      "source": [
        "# Emission Matrix\n",
        "emission_matrix = []\n",
        "number_of_states = 1 + int(max(list_of_token))\n",
        "temp_matrix = np.zeros(shape=(number_of_hidden_states,number_of_states))\n",
        "\n",
        "temp = True\n",
        "for i in range(0,number_of_states):\n",
        "    list_of_index = list(np.where(list_of_token==i)[0])\n",
        "    for index in list_of_index:\n",
        "      word = LE_1.inverse_transform([list_of_token[index]])[0]\n",
        "      l_idx = LE_2.transform([word[0]])[0]\n",
        "      \n",
        "      temp_matrix[l_idx, list_of_token[index]] += 1\n",
        "\n",
        "temp_matrix /= np.expand_dims(temp_matrix.sum(1), axis=1)\n",
        "\n",
        "emission_matrix = temp_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwtrALfDDoLe"
      },
      "source": [
        "## We will use laplace smoothing \n",
        "- Laplace smoothing is a smoothing technique that handles the problem of zero probability in Naïve Bayes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMO2gKL3TE7B"
      },
      "source": [
        "def laplace_smoothing(matrix, count):\n",
        "  matrix[matrix!=0] = matrix[matrix!=0] + (1/count)\n",
        "  matrix[matrix==0] = 1/count\n",
        "  return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81fOVne7UQR8"
      },
      "source": [
        "transition_matrix = laplace_smoothing(transition_matrix, len(list_of_token_starting_letter))\n",
        "emission_matrix = laplace_smoothing(emission_matrix, len(list_of_token))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg8TOPu2EF3k"
      },
      "source": [
        "## Forward algorithm\n",
        "Calculate the total probability of all the observations (from t_1 ) up to time t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn7b3Sq32E4X"
      },
      "source": [
        "def forward(observations, transition_matrix, emission_matrix, initial_state_matrix):\n",
        "  T = len(observations)\n",
        "  M = len(transition_matrix)\n",
        "  alpha = np.zeros((T, M))\n",
        "  alpha[0, :] = [initial_state_matrix[i] * emission_matrix[i][0] for i in range(len(emission_matrix))]\n",
        "  for i in range(1, T):\n",
        "    for j in range(M):\n",
        "        alpha[i, j] = alpha[i-1].dot(transition_matrix[:][ j]) * emission_matrix[j][ observations[i]]\n",
        "\n",
        "  total_alpha = sum(max(alpha[i]) for i in range(T))\n",
        "  return total_alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUS-ahF2EHzM"
      },
      "source": [
        "## Backward algorithm\n",
        "Similarly calculate total probability of all the observations from final time (T) to t."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EikJj3wySxwQ"
      },
      "source": [
        "def backward(observations, transition_matrix, emission_matrix):\n",
        "  T = len(observations)\n",
        "  M = len(transition_matrix)\n",
        "\n",
        "  beta = np.zeros((T,M ))\n",
        "  beta[T - 1] = np.ones((M))\n",
        "\n",
        "  for i in range(T - 2, -1, -1): # backward from t-1 not t-2\n",
        "      for j in range(M): \n",
        "        beta[i, j] = (beta[i+1] * emission_matrix[:, list_of_token[i+1]]).dot(transition_matrix[j, :])\n",
        "      \n",
        "  total_beta = sum(max(beta[i]) for i in range(T))\n",
        "  return total_beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3pmu4wlRg3L"
      },
      "source": [
        "## Viterbi Decoding\n",
        "- parsing a sequence into the optimal series of hidden states\n",
        "- GIVEN  a sequence (list_of_token) and HMM model with transition_matrix, emission_matrix, initial_hidden_state_matrix\n",
        "- OUTPUT the sequence hidden states that maximizes probability\n",
        "- Viterbi algorithm, dynamic programming, max score over all paths, trace pointers find path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNS08TWlsnsb"
      },
      "source": [
        "def viterbi_decoding(list_of_token, transition_matrix=transition_matrix, emission_matrix=emission_matrix, initial_hidden_state_matrix=initial_hidden_state_matrix):\n",
        "  T = len(list_of_token)\n",
        "  M = transition_matrix.shape[0]\n",
        "\n",
        "  omega = np.zeros((T, M))\n",
        "  omega[0, :] = np.log(initial_hidden_state_matrix * emission_matrix[:, list_of_token[0]])\n",
        "\n",
        "  #forward\n",
        "  prev = np.zeros((T - 1, M))\n",
        "  for i in range(1, T):\n",
        "    for j in range(M):\n",
        "      probability = omega[i - 1] + np.log(transition_matrix[:, j]) + np.log(emission_matrix[j, list_of_token[i]])\n",
        "      prev[i-1, j] = np.argmax(probability)\n",
        "      omega[i, j] = np.max(probability)\n",
        "\n",
        "  S = np.zeros(T)\n",
        "  last_state = np.argmax(omega[T - 1, :])\n",
        "\n",
        "  #backward\n",
        "  S[0] = last_state\n",
        "  backtrack_index = 1\n",
        "  for i in range(T - 2, -1, -1):\n",
        "      S[backtrack_index] = prev[i, int(last_state)]\n",
        "      last_state = prev[i, int(last_state)]\n",
        "      backtrack_index += 1\n",
        "      \n",
        "  S = np.flip(S, axis=0)\n",
        "  S = S.astype(int)\n",
        "  hidden_state_list = LE_2.inverse_transform(S)\n",
        "  \n",
        "  return hidden_state_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7-6q3HeSRHZ"
      },
      "source": [
        "sentence = \"to be \"\n",
        "observations = []\n",
        "for word in sentence.split():\n",
        "  try:\n",
        "    le_class = LE_1.transform([word])[0]\n",
        "    observations.append(le_class)\n",
        "  except:\n",
        "    raise ValueError(\"Cannot find the word at the corpus\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrsiAJnSHrA7",
        "outputId": "c051bef2-2b89-49c6-d67e-32deac391933"
      },
      "source": [
        "sentence_hidden_state = viterbi_decoding(observations)\n",
        "print(f\"Hidden state of '{sentence}'\")\n",
        "print(sentence_hidden_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden state of 'to be '\n",
            "['t' 'b']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX37JPAVFIuM"
      },
      "source": [
        "Looks good! We will use this as a base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwn_G5i5FSDl"
      },
      "source": [
        "## Generate future sentence\n",
        "With viterbi algorithm, we get the best future sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8cbDh0PKCE-"
      },
      "source": [
        "import numpy as np\n",
        "def ViterbiAlgo(transition_matrix, emission_matrix, observations):\n",
        "    T = len(observations)\n",
        "    M = len(transition_matrix)\n",
        "\n",
        "    probs = np.zeros(M)\n",
        "\n",
        "    paths = np.zeros( (M, T+1 ))\n",
        "    paths[:, 0] = np.arange(M)\n",
        "\n",
        "    for obs_ind, obs_val in enumerate(observations):\n",
        "        for state_ind in range(M):\n",
        "            val = 0\n",
        "            if obs_val< np.size(emission_matrix,1):\n",
        "                val = np.log(emission_matrix[state_ind][obs_val])\n",
        "            temp_probs = probs + val + np.log(transition_matrix[:][state_ind])\n",
        "            best_temp_ind = np.argmax(temp_probs)\n",
        "            paths[state_ind,:] = paths[best_temp_ind,:]\n",
        "            paths[state_ind,(obs_ind+1)] = state_ind\n",
        "            probs[state_ind] = temp_probs[best_temp_ind]\n",
        "    best_path_ind = np.argmax(probs)\n",
        "    \n",
        "    return (paths[best_path_ind].astype(int), probs[best_path_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGzJpmxwTXJX",
        "outputId": "ecddf6a8-ff65-40a5-f5a1-09b489061c68"
      },
      "source": [
        "generated_sequence , _ =  ViterbiAlgo(transition_matrix, emission_matrix, observations)\n",
        "\n",
        "given_seq = LE_1.inverse_transform(observations)\n",
        "print(f\"Future sequence of '{' '.join(given_seq)}' is\")\n",
        "ans = np.append(given_seq,LE_1.inverse_transform(generated_sequence))\n",
        "print(\" \".join(ans))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future sequence of 'to be' is\n",
            "to be care care accents\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlILdObqRcjW"
      },
      "source": [
        "Quite gibberish. But, I am satisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKvZdULWb1vk"
      },
      "source": [
        "## Generate Best Sequence with length 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHid1vLTug2k"
      },
      "source": [
        "import operator\n",
        "def forward_backward(states, s_pro, t_pro, e_pro, length=3):\n",
        "  path = { s:[] for s in states} # init path: path[s] represents the path ends with s\n",
        "  path_prob = { s:[] for s in states} \n",
        "\n",
        "  num_hidden_state  = len(e_pro)\n",
        "  num_emission = len(e_pro[0])\n",
        "\n",
        "  all_prob = {}\n",
        "  for i in range(length):\n",
        "    all_prob[i] = {}\n",
        "    for emis_ind in range(num_emission):\n",
        "      all_prob[i][emis_ind] = []\n",
        "\n",
        "  # Initialize prob\n",
        "  initial_prob = {} \n",
        "  for emis_ind in range(num_emission): # words (emissions)\n",
        "    max_emission_prob , max_state = -1, -1\n",
        "    for s in states:\n",
        "      start = (s_pro[s])\n",
        "      emis = e_pro[s][emis_ind]\n",
        "      result = start*emis\n",
        "      if max_emission_prob < result:\n",
        "        max_emission_prob = result\n",
        "        max_state = s\n",
        "    all_prob[0][emis_ind].append((max_emission_prob , max_state))\n",
        "\n",
        "  # Get the rest of the probability\n",
        "  for i in range(1, length):\n",
        "    last_pro = all_prob[i-1]\n",
        "    for emis_ind in range(num_emission):\n",
        "      for curr_state in states:\n",
        "        # Get maximum \n",
        "        max_pro , max_last_sta = -1, None\n",
        "        temp_emis_ind = 0\n",
        "        for last_state in states:\n",
        "          prev_prob, prev_state = last_pro[temp_emis_ind][0]\n",
        "          trans = t_pro[last_state][curr_state]\n",
        "          emis = e_pro[curr_state][emis_ind]\n",
        "          result = prev_prob*trans*emis\n",
        "          temp_emis_ind +=1\n",
        "          if max_pro < result:\n",
        "            max_pro = result\n",
        "            max_last_sta = last_state\n",
        "\n",
        "        all_prob[i][emis_ind].append((max_pro , max_last_sta))\n",
        "  \n",
        "  ans = []\n",
        "  for i in range(length):\n",
        "    max_prob, max_emis_index = -1 , -1\n",
        "    for key in all_prob[i]:\n",
        "      for prob, _ in all_prob[i][key]:\n",
        "        if max_prob < prob:\n",
        "          max_prob = prob\n",
        "          max_emis_index = key\n",
        "    ans.append(max_emis_index)\n",
        "  return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9EEXYOLp7Lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be6534b-9780-403e-ce9c-0d9928c57f2f"
      },
      "source": [
        "generated_sequence = forward_backward(list(set(list_of_token_starting_letter)), initial_state_matrix, transition_matrix, emission_matrix  )\n",
        "generated_sequence = LE_1.inverse_transform(generated_sequence)\n",
        "print(\"Generated sequence is \")\n",
        "print(\" \".join(generated_sequence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated sequence is \n",
            "entrance of of\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}